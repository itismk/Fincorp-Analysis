{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b49c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac2476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2ccf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a402657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Domain', 'Complaint/ Opinion', 'Complaint Label', 'Severity level',\n",
      "       'Sentiment', 'Emotion', 'Intent', 'Unnamed: 7', 'Unnamed: 8', '2',\n",
      "       'Unnamed: 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"FINCORP.csv\")\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Complaint/ Opinion\"])\n",
    "X = tokenizer.texts_to_sequences(data[\"Complaint/ Opinion\"])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4510d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in Intent with counts:\n",
      "                 count  count\n",
      "0           Assistance    394\n",
      "1             Feedback    235\n",
      "2                Query    171\n",
      "3              General    131\n",
      "4           Suggestion     87\n",
      "5     Feedback/General      2\n",
      "6  Feedback/Sugeestion      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_unique_elements_with_counts(csv_file, columns):\n",
    "   \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    \n",
    "    unique_elements_with_counts = {}\n",
    "    for column in columns:\n",
    "        unique_elements_with_counts[column] = df[column].value_counts().reset_index().rename(columns={column: 'count', 'index': column})\n",
    "\n",
    "    return unique_elements_with_counts\n",
    "csv_file_path = 'synthe.csv'\n",
    "columns_to_check = ['Intent']  \n",
    "result = get_unique_elements_with_counts(csv_file_path, columns_to_check)\n",
    "\n",
    "\n",
    "for column, df in result.items():\n",
    "    print(f\"Unique elements in {column} with counts:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9466ba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in Intent with counts:\n",
      "        count  count\n",
      "0    Feedback   1000\n",
      "1  Assistance   1000\n",
      "2     General   1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_unique_elements_with_counts(csv_file, columns):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    unique_elements_with_counts = {}\n",
    "    for column in columns:\n",
    "        unique_elements_with_counts[column] = df[column].value_counts().reset_index().rename(columns={column: 'count', 'index': column})\n",
    "\n",
    "    return unique_elements_with_counts\n",
    "\n",
    "csv_file_path = 'shuffled_data.csv'\n",
    "columns_to_check = ['Intent']  \n",
    "result = get_unique_elements_with_counts(csv_file_path, columns_to_check)\n",
    "for column, df in result.items():\n",
    "    print(f\"Unique elements in {column} with counts:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb14de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "daef9720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bce196926b344e8b471b7ee95702576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b1583a4b604816a544566dd9df9faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5431009d20344ada94371f27d96e95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16739d943fc44e349edf0c5cb982bff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea526eb8f9d4a859639456418fee96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfa28fec7fe4d498620f89925d40520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab749e93e6354277870c9728ac8b4e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61c9c29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: torch in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: pandas in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: nltk in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/siddharthparasher/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch pandas scikit-learn nltk tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a381038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 60] Operation\n",
      "[nltk_data]     timed out>\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc24a28365343148af8ec54acc2d262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "batch_text_or_text_pairs has to be a list or a tuple (got <class 'numpy.ndarray'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Tokenize the input text\u001b[39;00m\n\u001b[1;32m     78\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m     80\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplaint/ Opinion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     81\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m     pad_to_max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     85\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     86\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Encode labels\u001b[39;00m\n\u001b[1;32m     90\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2825\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2816\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2817\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2818\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2823\u001b[0m )\n\u001b[0;32m-> 2825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m   2826\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2827\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   2828\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m   2829\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   2830\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m   2831\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[1;32m   2832\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[1;32m   2833\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m   2834\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m   2835\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m   2836\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m   2837\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m   2838\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m   2839\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m   2840\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m   2841\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2843\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:265\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m )\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:415\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batch_encode_plus\u001b[39m(\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    395\u001b[0m     batch_text_or_text_pairs: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    413\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_text_or_text_pairs, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_text_or_text_pairs has to be a list or a tuple (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(batch_text_or_text_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    421\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    422\u001b[0m         truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    426\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: batch_text_or_text_pairs has to be a list or a tuple (got <class 'numpy.ndarray'>)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "back_translation_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "back_translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "def back_translate_augment(text):\n",
    "    \n",
    "    input_ids = back_translation_tokenizer.encode(text, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translated_ids = back_translation_model.generate(input_ids)\n",
    "    \n",
    "    \n",
    "    translated_text = back_translation_tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "\n",
    "data_path = \"shuffled_data.csv\"\n",
    "\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "data = data.dropna(subset=[\"Intent\"])\n",
    "\n",
    "\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(back_translate_augment)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(preprocess_text)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    data[\"Complaint/ Opinion\"].values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[\"Intent\"])\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "\n",
    "input_ids = encoded_data[\"input_ids\"]\n",
    "attention_mask = encoded_data[\"attention_mask\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    range(len(input_ids)), labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(input_ids[X_train], attention_mask[X_train], y_train)\n",
    "test_dataset = TensorDataset(input_ids[X_test], attention_mask[X_test], y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_encoder.classes_), output_hidden_states=False)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)\n",
    "\n",
    "intent_class_counts = data.groupby(\"Intent\")[\"Complaint/ Opinion\"].value_counts().unstack()\n",
    "class_weights = 1.0 / intent_class_counts.sum(axis=1)\n",
    "class_weights = torch.tensor(class_weights)\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10  \n",
    "early_stopping_counter = 0\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validation\"):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_validation_loss += loss.item()\n",
    "\n",
    "    average_validation_loss = total_validation_loss / len(test_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {average_validation_loss}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if average_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = average_validation_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= 3:\n",
    "            print(\"Early stopping! No improvement in validation loss.\")\n",
    "            break\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_predictions.extend(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97673e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/siddharthparasher/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/siddharthparasher/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|█████████████████████████████| 628/628 [13:21<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Training Loss: 1.6407473480245869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████| 158/158 [00:42<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Validation Loss: 1.57763932324663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████| 628/628 [13:50<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Training Loss: 1.5581934850686674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████| 158/158 [00:40<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Validation Loss: 1.612440279012994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████| 628/628 [12:02<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Training Loss: 1.5236258204955204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████| 158/158 [00:39<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Validation Loss: 1.5795849222171157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|███████████████████████████| 628/628 [3:03:16<00:00, 17.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Training Loss: 1.4755914628885354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████| 158/158 [2:02:20<00:00, 46.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Validation Loss: 1.6224808730656588\n",
      "Early stopping! No improvement in validation loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████| 158/158 [08:45<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2967382657120127\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 5, does not match size of target_names, 8. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 171\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Print detailed classification report\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(true_labels, all_predictions, target_names\u001b[38;5;241m=\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2561\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2557\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2558\u001b[0m             )\n\u001b[1;32m   2559\u001b[0m         )\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2564\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 8. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"FINCORP_last.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "#data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "#data = data.dropna(subset=[\"Intent\"])\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Handle the case when the input is not a string (NaN or other)\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and extra whitespaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply text preprocessing to \"Complaint/ Opinion\" attribute\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    data[\"Complaint/ Opinion\"].values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[\"Intent \"])\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Split the data\n",
    "input_ids = encoded_data[\"input_ids\"]\n",
    "attention_mask = encoded_data[\"attention_mask\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    range(len(input_ids)), labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(input_ids[X_train], attention_mask[X_train], y_train)\n",
    "test_dataset = TensorDataset(input_ids[X_test], attention_mask[X_test], y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize RoBERTa model with dropout\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_encoder.classes_))\n",
    "model.dropout = torch.nn.Dropout(0.2)  # Increased dropout\n",
    "\n",
    "# Set up optimizer and scheduler with adjusted learning rate\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)  # Adjusted learning rate\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.9)  # Learning rate scheduler\n",
    "\n",
    "# Define loss function with adjusted class weights\n",
    "class_weights = 1.0 / torch.bincount(labels)\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training loop with early stopping\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10  # Increased number of epochs\n",
    "early_stopping_counter = 0\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validation\"):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_validation_loss += loss.item()\n",
    "\n",
    "    average_validation_loss = total_validation_loss / len(test_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {average_validation_loss}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if average_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = average_validation_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= 3:\n",
    "            print(\"Early stopping! No improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_predictions.extend(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, all_predictions, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fa650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68716f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eae63d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Domain', 'Complaint/ Opinion', 'Complaint Label', 'Severity level',\n",
      "       'Sentiment', 'Emotion', 'Intent', 'Unnamed: 7', 'Unnamed: 8', '2',\n",
      "       'Unnamed: 10'],\n",
      "      dtype='object')\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 6s 52ms/step - loss: 1.0704 - accuracy: 0.3864 - val_loss: 1.0734 - val_accuracy: 0.4036\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 5s 53ms/step - loss: 1.0665 - accuracy: 0.3960 - val_loss: 1.0793 - val_accuracy: 0.3921\n",
      "Epoch 3/10\n",
      "77/98 [======================>.......] - ETA: 1s - loss: 1.0571 - accuracy: 0.4294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     53\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"filtered_data.csv\")\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "# Preprocess the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Complaint/ Opinion\"])\n",
    "X = tokenizer.texts_to_sequences(data[\"Complaint/ Opinion\"])\n",
    "X = pad_sequences(X, padding='post')  # Add padding to sequences\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Confirm the column names\n",
    "print(data.columns)\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model...\n",
    "embedding_dim = 100  # Adjust as needed\n",
    "lstm_units = 150  # Adjust as needed\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=X.shape[1]))\n",
    "model.add(LSTM(lstm_units))\n",
    "model.add(Dense(units=len(set(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1f1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43dea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f00e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Complaint/ Opinion      Intent  \\\n",
      "0     Can someone tell me if transaction fail betwee...  Assistance   \n",
      "1     @LICIndiaForever @Paytmcare @Paytm As part of ...       Query   \n",
      "2     @ICICIBank_Care This is something very serious...  Assistance   \n",
      "4     Fraud transaction through CRED for SBI C-Card ...    Feedback   \n",
      "5     =A8 @ICICIBank @ICICIBank_Care I already made ...     General   \n",
      "...                                                 ...         ...   \n",
      "3594  @CryptoClash1 @BlocVaultAPP One of your revolu...  Assistance   \n",
      "3595  @pintuya14546019 Hi Pintu! We understand your ...  Assistance   \n",
      "3596  1st step.\\n\\nalready unlinked my debit card to...  Assistance   \n",
      "3597  @Dpk_is_here Hi Deepak! We understand your con...  Assistance   \n",
      "3598  @jyotish04 Hi Jyotish! We understand your conc...  Assistance   \n",
      "\n",
      "        Emotion   Priority  \n",
      "0       sadness       mild  \n",
      "1       sadness       high  \n",
      "2         anger  very high  \n",
      "4      surprise       mild  \n",
      "5         anger    unknown  \n",
      "...         ...        ...  \n",
      "3594      other    unknown  \n",
      "3595  happiness    unknown  \n",
      "3596       fear  very high  \n",
      "3597  happiness    unknown  \n",
      "3598  happiness    unknown  \n",
      "\n",
      "[1021 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "#data = pd.read_csv(\"FINCORP.csv\")\n",
    "\n",
    "# Mapping function\n",
    "def map_intent_emotion_to_priority(intent, emotion):\n",
    "    if intent in [\"Assistance\"] and emotion in [\"anger\", \"fear\",\"disgust\",\"surprise\"]:\n",
    "        return \"very high\"\n",
    "    elif intent in [\"Query\"] and emotion in [\"anger\", \"fear\", \"sadness\", \"other\",\"happiness\",\"surprise\"]:\n",
    "        return \"high\"\n",
    "    elif intent in [\"general\"] and emotion in [\"anger\", \"fear\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"Assistance\"] and emotion in [\"sadness\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"suggestion\", \"Feedback\",\"Feedback/Sugeestion\",\"Query\"] and emotion in [\"anger\", \"fear\", \"sadness\", \"other\",\"happiness\",\"surprise\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"General\",\"Feedback/General\"] and emotion in [ \"sadness\", \"other\",\"happiness\",\"surprise\"]:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply mapping to create Priority column\n",
    "data['Priority'] = data.apply(lambda row: map_intent_emotion_to_priority(row['Intent'], row['Emotion']), axis=1)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna(subset=['Intent', 'Emotion'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data[['Complaint/ Opinion', 'Intent', 'Emotion', 'Priority']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ec0a9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have loaded the data using pd.read_csv(\"FINCORP.csv\")\n",
    "# Replace the file path with the actual path to your CSV file\n",
    "#data = pd.read_csv(\"FINCORP.csv\")\n",
    "\n",
    "# Mapping function\n",
    "def map_intent_emotion_to_priority(intent, emotion):\n",
    "    if intent in [\"Assistance\"] and emotion in [\"anger\", \"fear\", \"disgust\", \"surprise\"]:\n",
    "        return \"very high\"\n",
    "    elif intent in [\"Query\"] and emotion in [\"anger\", \"fear\", \"sadness\", \"other\", \"happiness\", \"surprise\"]:\n",
    "        return \"high\"\n",
    "    elif intent in [\"general\"] and emotion in [\"anger\", \"fear\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"Assistance\"] and emotion in [\"sadness\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"suggestion\", \"Feedback\", \"Feedback/Suggestion\", \"Query\"] and emotion in [\"anger\", \"fear\", \"sadness\", \"other\", \"happiness\", \"surprise\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"General\", \"Feedback/General\"] and emotion in [\"sadness\", \"other\", \"happiness\", \"surprise\"]:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply mapping to create Priority column\n",
    "data['Priority'] = data.apply(lambda row: map_intent_emotion_to_priority(row['Intent'], row['Emotion']), axis=1)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna(subset=['Intent', 'Emotion'])\n",
    "\n",
    "# Plotting the mapping with rotated X-axis labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(data['Intent'], data['Emotion'], c=data['Priority'].astype('category').cat.codes, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.title('Mapping of Intent and Emotion to Priority')\n",
    "plt.xlabel('Intent')\n",
    "plt.ylabel('Emotion')\n",
    "plt.colorbar(scatter, label='Priority')\n",
    "\n",
    "# Rotate X-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6ca8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Emotions: ['sadness' 'anger' 'surprise' 'fear' 'disgust' 'other' 'Fear' 'happiness']\n",
      "Unique Intents: ['Assistance' 'Query' nan 'Feedback' 'General' 'Feedback/General'\n",
      " 'Suggestion' 'Feedback/Sugeestion']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "#data = pd.read_csv(\"FINCORP.csv\")\n",
    "\n",
    "# Get unique values in the 'Emotion' column\n",
    "unique_emotions = data['Emotion'].unique()\n",
    "print(\"Unique Emotions:\", unique_emotions)\n",
    "\n",
    "# Get unique values in the 'Intent' column\n",
    "unique_intents = data['Intent'].unique()\n",
    "print(\"Unique Intents:\", unique_intents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ff534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35503b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fe185c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Domain', 'Complaint/ Opinion', 'Complaint Label', 'Severity level',\n",
      "       'Sentiment', 'Emotion', 'Intent', 'Unnamed: 7', 'Unnamed: 8', '2',\n",
      "       'Unnamed: 10'],\n",
      "      dtype='object')\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 4s 47ms/step - loss: 1.0592 - accuracy: 0.5263 - val_loss: 1.0370 - val_accuracy: 0.5667\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 1.0287 - accuracy: 0.5400 - val_loss: 1.0335 - val_accuracy: 0.5667\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 1.0231 - accuracy: 0.5400 - val_loss: 1.0212 - val_accuracy: 0.5667\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 1.0219 - accuracy: 0.5400 - val_loss: 1.0338 - val_accuracy: 0.5667\n",
      "Epoch 5/10\n",
      "57/69 [=======================>......] - ETA: 0s - loss: 1.0172 - accuracy: 0.5422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     61\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"tabular-actgan-65747db80bf737e9588d2b05-data_preview.csv\")\n",
    "# Merge \"Query\" and \"General\" into \"General\"\n",
    "data[\"Intent\"].replace({\"Query\": \"General\"}, inplace=True)\n",
    "\n",
    "# Merge \"Feedback\" and \"Suggestion\" into \"Feedback\"\n",
    "data[\"Intent\"].replace({\"Feedback\": \"Feedback/Suggestion\"}, inplace=True)\n",
    "\n",
    "# Remove rows with classes \"General\" and \"Feedback/Suggestion\"\n",
    "data = data[~data[\"Intent\"].isin([\"Feedback/General\", \"Feedback/Suggestion\"])]\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "data = data.dropna(subset=['Intent', 'Emotion'])\n",
    "# Preprocess the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Complaint/ Opinion\"])\n",
    "X = tokenizer.texts_to_sequences(data[\"Complaint/ Opinion\"])\n",
    "X = pad_sequences(X, padding='post')  # Add padding to sequences\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Confirm the column names\n",
    "print(data.columns)\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n",
    "\n",
    "# Build the model...\n",
    "embedding_dim = 100  # Adjust as needed\n",
    "lstm_units = 150  # Adjust as needed\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=X.shape[1]))\n",
    "model.add(LSTM(lstm_units))\n",
    "model.add(Dense(units=len(set(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Map Intent and Emotion to Priority\n",
    "def map_intent_emotion_to_priority(intent, emotion):\n",
    "    if intent in [\"assistance\"] and emotion in [\"anger\", \"fear\"]:\n",
    "        return \"high\"\n",
    "    elif intent in [\"suggestion\", \"feedback\"] and emotion in [\"anger\", \"fear\", \"sadness\", \"other\"]:\n",
    "        return \"mild\"\n",
    "    elif intent in [\"general\"]:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply mapping to create Priority column\n",
    "data['Priority'] = data.apply(lambda row: map_intent_emotion_to_priority(row['Intent'], row['Emotion']), axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fce0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Return preprocessed text\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3319e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a005c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Domain', 'Complaint/ Opinion', 'Complaint Label', 'Severity level',\n",
      "       'Sentiment', 'Emotion', 'Intent', 'Unnamed: 7', 'Unnamed: 8', '2',\n",
      "       'Unnamed: 10'],\n",
      "      dtype='object')\n",
      "Epoch 1/10\n",
      "45/98 [============>.................] - ETA: 6:38 - loss: 1.5553 - accuracy: 0.3049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_tfidf, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_tfidf, y_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"tabular-actgan-65747db80bf737e9588d2b05-data_preview.csv\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna(subset=['Intent', 'Emotion'])\n",
    "\n",
    "# Filter for specific intent classes\n",
    "valid_intent_classes = [\"General\", \"Feedback\", \"Query\", \"Suggestion\", \"Assistance\"]\n",
    "data = data[data['Intent'].isin(valid_intent_classes)]\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "# Preprocess the \"Complaint/ Opinion\" attribute\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(preprocess_text)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data[\"Complaint/ Opinion\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert sparse matrix to NumPy array\n",
    "X_tfidf_array = X_tfidf.toarray()\n",
    "\n",
    "# Confirm the column names\n",
    "print(data.columns)\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf_array, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model with Bidirectional LSTM\n",
    "embedding_dim = 100  # Adjust as needed\n",
    "lstm_units = 150  # Adjust as needed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=X_tfidf_array.shape[1], output_dim=embedding_dim, input_length=X_tfidf_array.shape[1]))\n",
    "model.add(Bidirectional(LSTM(lstm_units)))\n",
    "model.add(Dense(units=len(set(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46a90e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Domain                                 Complaint/ Opinion  \\\n",
      "0              Debit Card  hi jyotish we understand your concern you can ...   \n",
      "1        Customer Service  from the suggested portal reply received conta...   \n",
      "2              Netbanking        months days to loan application no response   \n",
      "3              Debit Card  hi arun we understand your concern you can dep...   \n",
      "4        Transaction Fail  the digital experience even for a simple trans...   \n",
      "...                   ...                                                ...   \n",
      "4995           Debit Card  sorry for my english but i wanna try because i...   \n",
      "4996  Transaction Failure  but why the sms says its from icici has someon...   \n",
      "4997     Customer Service  im unable to make any transaction using my cre...   \n",
      "4998               Salary  hi jyotish we understand your concern you can ...   \n",
      "4999     Transaction Fail  getting error during net banking transaction a...   \n",
      "\n",
      "      Complaint Label        Severity level Sentiment  Emotion      Intent  \\\n",
      "0                   0         Non-Complaint   neutral    other     General   \n",
      "1                   1  No explicit reproach  negative    anger    Feedback   \n",
      "2                   1           Disapproval  negative  sadness       Query   \n",
      "3                   0                 Blame  negative  sadness     General   \n",
      "4                   1                 Blame  negative    anger  Assistance   \n",
      "...               ...                   ...       ...      ...         ...   \n",
      "4995                0                 Blame  negative    anger    Feedback   \n",
      "4996                1  No explicit reproach  negative  sadness       Query   \n",
      "4997                1           Disapproval  negative  sadness  Suggestion   \n",
      "4998                1            Accusation  positive  sadness     General   \n",
      "4999                1                 Blame  negative  sadness       Query   \n",
      "\n",
      "      Unnamed: 7  Unnamed: 8   2 Unnamed: 10  \n",
      "0            NaN         NaN NaN         NaN  \n",
      "1            NaN         NaN NaN         NaN  \n",
      "2            NaN         NaN NaN         NaN  \n",
      "3            NaN         NaN NaN         NaN  \n",
      "4            NaN         NaN NaN         NaN  \n",
      "...          ...         ...  ..         ...  \n",
      "4995         NaN         NaN NaN         NaN  \n",
      "4996         NaN         NaN NaN         NaN  \n",
      "4997         NaN         NaN NaN         NaN  \n",
      "4998         NaN         NaN NaN         NaN  \n",
      "4999         NaN         NaN NaN         NaN  \n",
      "\n",
      "[5000 rows x 11 columns]\n",
      "Test Accuracy: 0.286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"tabular-actgan-65747db80bf737e9588d2b05-data_preview.csv\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna(subset=['Intent', 'Emotion'])\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "# Preprocess the \"Complaint/ Opinion\" attribute\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(preprocess_text)\n",
    "print(data)\n",
    "# Use TF-IDF vectorizer to convert text data to numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the max_features parameter\n",
    "X = vectorizer.fit_transform(data[\"Complaint/ Opinion\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b15f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your training history (replace this with your actual training history)\n",
    "history = {\n",
    "    'loss': [0.8126, 0.6804, 0.6819, 0.6818, 0.6795, 0.6795, 0.6802, 0.6808, 0.6804, 0.6798],\n",
    "    'accuracy': [0.8288, 0.8408, 0.8408, 0.8408, 0.8408, 0.8408, 0.8408, 0.8408, 0.8408, 0.8408],\n",
    "    'val_loss': [0.7122, 0.7060, 0.7140, 0.7082, 0.7060, 0.7061, 0.7076, 0.7140, 0.7057, 0.7055],\n",
    "    'val_accuracy': [0.8308, 0.8308, 0.8308, 0.8308, 0.8308, 0.8308, 0.8308, 0.8308, 0.8308, 0.8308]\n",
    "}\n",
    "\n",
    "# Plot training loss and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training accuracy and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e627b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 60] Operation\n",
      "[nltk_data]     timed out>\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|█████████████████████████████| 300/300 [04:56<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Training Loss: 1.1007412906487783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████| 75/75 [00:18<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Validation Loss: 1.103010261853536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████| 300/300 [04:56<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Training Loss: 1.0986580276489257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████| 75/75 [00:16<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Validation Loss: 1.1000519212086994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████| 300/300 [04:57<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Training Loss: 1.096458848118782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████| 75/75 [00:18<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Validation Loss: 1.102331142425537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████| 300/300 [04:56<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Training Loss: 1.0925002437829971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████| 75/75 [00:17<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Validation Loss: 1.1036490058898927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████| 300/300 [04:58<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Training Loss: 1.0879595319430033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████| 75/75 [00:18<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Validation Loss: 1.1109206088383992\n",
      "Early stopping! No improvement in validation loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 75/75 [00:18<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.31833333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"shuffled_data.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "data = data.dropna(subset=[\"Intent\"])\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Handle the case when the input is not a string (NaN or other)\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and extra whitespaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply text preprocessing to \"Complaint/ Opinion\" attribute\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    data[\"Complaint/ Opinion\"].values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[\"Intent\"])\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Split the data\n",
    "input_ids = encoded_data[\"input_ids\"]\n",
    "attention_mask = encoded_data[\"attention_mask\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    range(len(input_ids)), labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(input_ids[X_train], attention_mask[X_train], y_train)\n",
    "test_dataset = TensorDataset(input_ids[X_test], attention_mask[X_test], y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize RoBERTa model with dropout\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_encoder.classes_))\n",
    "model.dropout = torch.nn.Dropout(0.2)  # Increased dropout\n",
    "\n",
    "# Set up optimizer and scheduler with adjusted learning rate\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)  # Adjusted learning rate\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.9)  # Learning rate scheduler\n",
    "\n",
    "# Define loss function with adjusted class weights\n",
    "class_weights = 1.0 / torch.bincount(labels)\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training loop with early stopping\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10  # Increased number of epochs\n",
    "early_stopping_counter = 0\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validation\"):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_validation_loss += loss.item()\n",
    "\n",
    "    average_validation_loss = total_validation_loss / len(test_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {average_validation_loss}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if average_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = average_validation_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= 3:\n",
    "            print(\"Early stopping! No improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_predictions.extend(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9011da1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/siddharthparasher/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|█████████████████████████████| 500/500 [09:13<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Training Loss: 1.0319575681686401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████| 125/125 [00:28<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Validation Loss: 1.0310066957473756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████| 500/500 [16:48<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Training Loss: 1.0096377865076065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████████████████████| 125/125 [00:27<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Validation Loss: 1.013351683616638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  44%|████████████▋                | 219/500 [39:38<50:51, 10.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     80\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 82\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     83\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     85\u001b[0m average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"shuffled_data.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "data = data.dropna(subset=[\"Intent\"])\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    data[\"Complaint/ Opinion\"].values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[\"Intent\"])\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Split the data\n",
    "input_ids = encoded_data[\"input_ids\"]\n",
    "attention_mask = encoded_data[\"attention_mask\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    range(len(input_ids)), labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(input_ids[X_train], attention_mask[X_train], y_train)\n",
    "test_dataset = TensorDataset(input_ids[X_test], attention_mask[X_test], y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize RoBERTa model with dropout\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_encoder.classes_))\n",
    "model.dropout = torch.nn.Dropout(0.2)  # Increased dropout\n",
    "\n",
    "# Set up optimizer and scheduler with adjusted learning rate\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)  # Adjusted learning rate\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.9)  # Learning rate scheduler\n",
    "\n",
    "# Define loss function with adjusted class weights\n",
    "class_weights = 1.0 / torch.bincount(labels)\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training loop with early stopping\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10  # Increased number of epochs\n",
    "early_stopping_counter = 0\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Validation\"):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_validation_loss += loss.item()\n",
    "\n",
    "    average_validation_loss = total_validation_loss / len(test_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {average_validation_loss}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if average_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = average_validation_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= 3:\n",
    "            print(\"Early stopping! No improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_predictions.extend(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c31b9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"tabular-actgan-65747db80bf737e9588d2b05-data_preview.csv\")\n",
    "\n",
    "# Merge \"Query\" and \"General\" into \"General\"\n",
    "data[\"Intent\"].replace({\"Query\": \"General\"}, inplace=True)\n",
    "\n",
    "# Merge \"Feedback\" and \"Suggestion\" into \"Feedback\"\n",
    "data[\"Intent\"].replace({\"Suggestion\": \"Feedback\"}, inplace=True)\n",
    "\n",
    "# Remove rows with classes \"General\" and \"Feedback/Suggestion\"\n",
    "data = data[~data[\"Intent\"].isin([\"Feedback/General\", \"Feedback/Suggestion\"])]\n",
    "\n",
    "# Save the manipulated data to a new CSV file\n",
    "data.to_csv(\"manipulated_data1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "530ee06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent\n",
      "Feedback               1970\n",
      "General                1871\n",
      "Assistance             1050\n",
      "Feedback/Sugeestion      46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"manipulated_data1.csv\")\n",
    "\n",
    "# Get unique elements and their count in the \"Intent\" attribute\n",
    "intent_counts = data[\"Intent\"].value_counts()\n",
    "\n",
    "# Display the unique elements and their count\n",
    "print(intent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7e42cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"manipulated_data1.csv\")\n",
    "\n",
    "# Drop rows with \"Feedback/Sugeestion\" in the \"Intent\" attribute\n",
    "data = data[data[\"Intent\"] != \"Feedback/Sugeestion\"]\n",
    "\n",
    "# Save the modified data to a new CSV file\n",
    "data.to_csv(\"filtered_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8758eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent\n",
      "General       2367\n",
      "Feedback      1762\n",
      "Assistance     871\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"15DEC.csv\")\n",
    "\n",
    "# Get unique elements and their count in the \"Intent\" attribute\n",
    "intent_counts = data[\"Intent\"].value_counts()\n",
    "\n",
    "# Display the unique elements and their count\n",
    "print(intent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ae1a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"filtered_data.csv\")\n",
    "\n",
    "# Get 1000 entries for each unique value in the \"Intent\" attribute\n",
    "sampled_data = data.groupby(\"Intent\").apply(lambda x: x.sample(n=1000, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Save the sampled data to a new CSV file\n",
    "sampled_data.to_csv(\"sampled_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64723564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the sampled CSV file\n",
    "sampled_data = pd.read_csv(\"sampled_data.csv\")\n",
    "\n",
    "# Shuffle the rows\n",
    "shuffled_data = sampled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the shuffled data to a new CSV file\n",
    "shuffled_data.to_csv(\"shuffled_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c67b5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 5s 34ms/step - loss: 1.1086 - accuracy: 0.3481 - val_loss: 1.0856 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0857 - accuracy: 0.3956 - val_loss: 1.0773 - val_accuracy: 0.3938\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0804 - accuracy: 0.3978 - val_loss: 1.0622 - val_accuracy: 0.4487\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0756 - accuracy: 0.4109 - val_loss: 1.0872 - val_accuracy: 0.3925\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0667 - accuracy: 0.4347 - val_loss: 1.0637 - val_accuracy: 0.4263\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0615 - accuracy: 0.4372 - val_loss: 1.0833 - val_accuracy: 0.3950\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 1.0622 - accuracy: 0.4390\n",
      "Test Accuracy: 0.4390000104904175\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"NAALC.csv\")\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "# Preprocess the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Complaint/ Opinion\"])\n",
    "X = tokenizer.texts_to_sequences(data[\"Complaint/ Opinion\"])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Create an embedding matrix using pre-trained GloVe embeddings\n",
    "embeddings_index = {}\n",
    "embedding_dim = 100  # Adjust based on the chosen pre-trained embeddings\n",
    "with open('glove.6B/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=X.shape[1], trainable=False))\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=len(set(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the model if needed\n",
    "# model.save(\"best_intent_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aa1d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 9s 125ms/step - loss: 1.1004 - accuracy: 0.3700 - val_loss: 1.0923 - val_accuracy: 0.3700\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 5s 109ms/step - loss: 1.0907 - accuracy: 0.3919 - val_loss: 1.1123 - val_accuracy: 0.2950\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 6s 110ms/step - loss: 1.0837 - accuracy: 0.4066 - val_loss: 1.0559 - val_accuracy: 0.4575\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 1.0737 - accuracy: 0.4306 - val_loss: 1.0762 - val_accuracy: 0.4212\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 1.0707 - accuracy: 0.4328 - val_loss: 1.0836 - val_accuracy: 0.3975\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 1.0663 - accuracy: 0.4341 - val_loss: 1.0772 - val_accuracy: 0.4363\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 1.0584 - accuracy: 0.4620\n",
      "Test Accuracy: 0.4620000123977661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"NAALC.csv\")\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data[\"Complaint/ Opinion\"] = data[\"Complaint/ Opinion\"].fillna(\"\")\n",
    "\n",
    "# Preprocess the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Complaint/ Opinion\"])\n",
    "X = tokenizer.texts_to_sequences(data[\"Complaint/ Opinion\"])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Check and clean column names from potential whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Use the correct column name for the target variable\n",
    "y = label_encoder.fit_transform(data[\"Intent\"])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Create an embedding matrix using pre-trained GloVe embeddings\n",
    "embeddings_index = {}\n",
    "embedding_dim = 100  # Adjust based on the chosen pre-trained embeddings\n",
    "with open('glove.6B/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=X.shape[1], trainable=False))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=len(set(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the model if needed\n",
    "# model.save(\"best_intent_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73008b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b8282",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40c4cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/v7yx9x6d6xbg5bcbn67yzkt80000gn/T/ipykernel_51538/2913935028.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"Intent\"] = label_encoder_intent.fit_transform(df_subset[\"Intent\"])\n",
      "/var/folders/kg/v7yx9x6d6xbg5bcbn67yzkt80000gn/T/ipykernel_51538/2913935028.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"Emotion\"] = label_encoder_emotion.fit_transform(df_subset[\"Emotion\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 69ms/step - loss: 0.9935 - branch_intent_loss: 0.6642 - branch_emotion_loss: 0.3293 - branch_intent_accuracy: 0.2224 - branch_emotion_accuracy: 0.1212 - val_loss: 0.0296 - val_branch_intent_loss: 0.5982 - val_branch_emotion_loss: -0.5686 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -4.7260 - branch_intent_loss: 0.2273 - branch_emotion_loss: -4.9533 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -17.8458 - val_branch_intent_loss: -0.9860 - val_branch_emotion_loss: -16.8598 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 44ms/step - loss: -23.6138 - branch_intent_loss: -1.8255 - branch_emotion_loss: -21.7882 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -29.0710 - val_branch_intent_loss: -2.1937 - val_branch_emotion_loss: -26.8773 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: -32.5336 - branch_intent_loss: -2.9683 - branch_emotion_loss: -29.5653 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -36.4009 - val_branch_intent_loss: -3.0664 - val_branch_emotion_loss: -33.3345 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 36ms/step - loss: -39.4379 - branch_intent_loss: -3.9157 - branch_emotion_loss: -35.5222 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -42.3678 - val_branch_intent_loss: -3.8675 - val_branch_emotion_loss: -38.5003 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -44.9519 - branch_intent_loss: -4.7696 - branch_emotion_loss: -40.1823 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -47.0495 - val_branch_intent_loss: -4.5484 - val_branch_emotion_loss: -42.5011 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 35ms/step - loss: -49.3766 - branch_intent_loss: -5.5440 - branch_emotion_loss: -43.8326 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -51.0852 - val_branch_intent_loss: -5.2187 - val_branch_emotion_loss: -45.8665 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: -53.3407 - branch_intent_loss: -6.2918 - branch_emotion_loss: -47.0489 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -54.7598 - val_branch_intent_loss: -5.7980 - val_branch_emotion_loss: -48.9618 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -57.0160 - branch_intent_loss: -6.9290 - branch_emotion_loss: -50.0870 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -58.2793 - val_branch_intent_loss: -6.3320 - val_branch_emotion_loss: -51.9473 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -60.5469 - branch_intent_loss: -7.5419 - branch_emotion_loss: -53.0050 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -61.6961 - val_branch_intent_loss: -6.9129 - val_branch_emotion_loss: -54.7832 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: -64.0152 - branch_intent_loss: -8.2302 - branch_emotion_loss: -55.7851 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -64.9706 - val_branch_intent_loss: -7.4682 - val_branch_emotion_loss: -57.5024 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 36ms/step - loss: -67.3728 - branch_intent_loss: -8.8987 - branch_emotion_loss: -58.4742 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -68.1859 - val_branch_intent_loss: -8.0776 - val_branch_emotion_loss: -60.1083 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -70.6446 - branch_intent_loss: -9.5984 - branch_emotion_loss: -61.0462 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -71.3759 - val_branch_intent_loss: -8.6755 - val_branch_emotion_loss: -62.7004 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 35ms/step - loss: -73.8533 - branch_intent_loss: -10.2659 - branch_emotion_loss: -63.5874 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -74.4759 - val_branch_intent_loss: -9.2547 - val_branch_emotion_loss: -65.2212 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -77.0311 - branch_intent_loss: -10.9358 - branch_emotion_loss: -66.0952 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -77.5413 - val_branch_intent_loss: -9.8382 - val_branch_emotion_loss: -67.7031 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 37ms/step - loss: -80.1823 - branch_intent_loss: -11.6264 - branch_emotion_loss: -68.5559 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -80.5845 - val_branch_intent_loss: -10.4255 - val_branch_emotion_loss: -70.1589 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -83.2697 - branch_intent_loss: -12.2834 - branch_emotion_loss: -70.9864 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -83.5994 - val_branch_intent_loss: -11.0273 - val_branch_emotion_loss: -72.5721 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -86.3592 - branch_intent_loss: -12.9754 - branch_emotion_loss: -73.3838 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -86.5597 - val_branch_intent_loss: -11.6117 - val_branch_emotion_loss: -74.9480 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -89.3675 - branch_intent_loss: -13.6282 - branch_emotion_loss: -75.7393 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -89.5231 - val_branch_intent_loss: -12.1789 - val_branch_emotion_loss: -77.3442 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: -92.3871 - branch_intent_loss: -14.2660 - branch_emotion_loss: -78.1211 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -92.4391 - val_branch_intent_loss: -12.7441 - val_branch_emotion_loss: -79.6949 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -95.4051 - branch_intent_loss: -14.9293 - branch_emotion_loss: -80.4759 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -95.3352 - val_branch_intent_loss: -13.2869 - val_branch_emotion_loss: -82.0483 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 40ms/step - loss: -98.3357 - branch_intent_loss: -15.5406 - branch_emotion_loss: -82.7952 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -98.2194 - val_branch_intent_loss: -13.8291 - val_branch_emotion_loss: -84.3903 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -101.3236 - branch_intent_loss: -16.1714 - branch_emotion_loss: -85.1522 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -101.1106 - val_branch_intent_loss: -14.3706 - val_branch_emotion_loss: -86.7400 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -104.2894 - branch_intent_loss: -16.7807 - branch_emotion_loss: -87.5088 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -104.0508 - val_branch_intent_loss: -14.9261 - val_branch_emotion_loss: -89.1248 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -107.3296 - branch_intent_loss: -17.4081 - branch_emotion_loss: -89.9215 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -107.0193 - val_branch_intent_loss: -15.4220 - val_branch_emotion_loss: -91.5972 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: -110.3806 - branch_intent_loss: -17.9589 - branch_emotion_loss: -92.4217 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -110.0672 - val_branch_intent_loss: -15.9298 - val_branch_emotion_loss: -94.1373 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -113.5080 - branch_intent_loss: -18.5643 - branch_emotion_loss: -94.9437 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -113.0561 - val_branch_intent_loss: -16.4526 - val_branch_emotion_loss: -96.6036 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: -116.5668 - branch_intent_loss: -19.1903 - branch_emotion_loss: -97.3765 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -116.0778 - val_branch_intent_loss: -17.0326 - val_branch_emotion_loss: -99.0452 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -119.6548 - branch_intent_loss: -19.8644 - branch_emotion_loss: -99.7904 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -119.0501 - val_branch_intent_loss: -17.6062 - val_branch_emotion_loss: -101.4439 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -122.6814 - branch_intent_loss: -20.5156 - branch_emotion_loss: -102.1658 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - val_loss: -121.9944 - val_branch_intent_loss: -18.1662 - val_branch_emotion_loss: -103.8282 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915\n",
      "7/7 [==============================] - 0s 5ms/step - loss: -128.3022 - branch_intent_loss: -20.3119 - branch_emotion_loss: -107.9903 - branch_intent_accuracy: 0.3024 - branch_emotion_accuracy: 0.0878\n",
      "Test Loss: [-128.30224609375, -20.31194496154785, -107.99028015136719, 0.30243903398513794, 0.08780487626791]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming your DataFrame is named data\n",
    "# Select relevant columns\n",
    "df_subset = data[[\"Complaint/ Opinion\", \"Intent\", \"Emotion\"]]\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder_intent = LabelEncoder()\n",
    "df_subset[\"Intent\"] = label_encoder_intent.fit_transform(df_subset[\"Intent\"])\n",
    "\n",
    "label_encoder_emotion = LabelEncoder()\n",
    "df_subset[\"Emotion\"] = label_encoder_emotion.fit_transform(df_subset[\"Emotion\"])\n",
    "\n",
    "# Tokenize text data\n",
    "max_words = 1000  # adjust as needed\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(df_subset[\"Complaint/ Opinion\"].values)\n",
    "X = tokenizer.texts_to_sequences(df_subset[\"Complaint/ Opinion\"].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_intent, y_test_intent, y_train_emotion, y_test_emotion = train_test_split(\n",
    "    X, df_subset[\"Intent\"].values, df_subset[\"Emotion\"].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "embedding_dim = 50  # adjust as needed\n",
    "lstm_units = 50  # adjust as needed\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=X.shape[1])(input_layer)\n",
    "lstm_layer = LSTM(lstm_units)(embedding_layer)\n",
    "intent_output = Dense(1, activation='sigmoid', name='branch_intent')(lstm_layer)\n",
    "emotion_output = Dense(1, activation='sigmoid', name='branch_emotion')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[intent_output, emotion_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'branch_intent': y_train_intent, 'branch_emotion': y_train_emotion},\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(\n",
    "    X_test,\n",
    "    {'branch_intent': y_test_intent, 'branch_emotion': y_test_emotion}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb5973b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/v7yx9x6d6xbg5bcbn67yzkt80000gn/T/ipykernel_51538/1589323044.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"Intent\"] = label_encoder_intent.fit_transform(df_subset[\"Intent\"])\n",
      "/var/folders/kg/v7yx9x6d6xbg5bcbn67yzkt80000gn/T/ipykernel_51538/1589323044.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"Emotion\"] = label_encoder_emotion.fit_transform(df_subset[\"Emotion\"])\n",
      "/var/folders/kg/v7yx9x6d6xbg5bcbn67yzkt80000gn/T/ipykernel_51538/1589323044.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"Severity level\"] = label_encoder_severity.fit_transform(df_subset[\"Severity level\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 76ms/step - loss: 1.4842 - branch_intent_loss: 0.6526 - branch_emotion_loss: 0.1925 - branch_severity_loss: 0.6391 - branch_intent_accuracy: 0.2270 - branch_emotion_accuracy: 0.1196 - branch_severity_accuracy: 0.2040 - val_loss: -0.3050 - val_branch_intent_loss: 0.5103 - val_branch_emotion_loss: -1.2721 - val_branch_severity_loss: 0.4568 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: -7.1348 - branch_intent_loss: 0.0102 - branch_emotion_loss: -7.0672 - branch_severity_loss: -0.0778 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -16.8982 - val_branch_intent_loss: -0.5972 - val_branch_emotion_loss: -15.3125 - val_branch_severity_loss: -0.9884 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -21.3218 - branch_intent_loss: -1.1593 - branch_emotion_loss: -18.8349 - branch_severity_loss: -1.3276 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -27.2921 - val_branch_intent_loss: -1.5437 - val_branch_emotion_loss: -23.2214 - val_branch_severity_loss: -2.5271 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 33ms/step - loss: -30.9741 - branch_intent_loss: -2.2111 - branch_emotion_loss: -26.0563 - branch_severity_loss: -2.7067 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -36.4170 - val_branch_intent_loss: -2.4466 - val_branch_emotion_loss: -30.0049 - val_branch_severity_loss: -3.9655 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -39.3869 - branch_intent_loss: -3.2123 - branch_emotion_loss: -32.3040 - branch_severity_loss: -3.8706 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -43.9646 - val_branch_intent_loss: -3.2675 - val_branch_emotion_loss: -35.4682 - val_branch_severity_loss: -5.2289 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: -46.3084 - branch_intent_loss: -4.0853 - branch_emotion_loss: -37.2744 - branch_severity_loss: -4.9487 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -50.2044 - val_branch_intent_loss: -3.9161 - val_branch_emotion_loss: -39.8110 - val_branch_severity_loss: -6.4774 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 34ms/step - loss: -52.0310 - branch_intent_loss: -4.8017 - branch_emotion_loss: -41.2380 - branch_severity_loss: -5.9912 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -55.4561 - val_branch_intent_loss: -4.5610 - val_branch_emotion_loss: -43.3128 - val_branch_severity_loss: -7.5823 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: -56.9409 - branch_intent_loss: -5.5402 - branch_emotion_loss: -44.5083 - branch_severity_loss: -6.8925 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -60.1449 - val_branch_intent_loss: -5.1841 - val_branch_emotion_loss: -46.3904 - val_branch_severity_loss: -8.5704 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -61.4785 - branch_intent_loss: -6.2816 - branch_emotion_loss: -47.4759 - branch_severity_loss: -7.7209 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -64.5633 - val_branch_intent_loss: -5.8264 - val_branch_emotion_loss: -49.2431 - val_branch_severity_loss: -9.4938 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 36ms/step - loss: -65.7809 - branch_intent_loss: -7.0040 - branch_emotion_loss: -50.2690 - branch_severity_loss: -8.5079 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -68.8446 - val_branch_intent_loss: -6.4323 - val_branch_emotion_loss: -52.0195 - val_branch_severity_loss: -10.3928 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: -70.0493 - branch_intent_loss: -7.7113 - branch_emotion_loss: -53.0612 - branch_severity_loss: -9.2769 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -73.1460 - val_branch_intent_loss: -7.0461 - val_branch_emotion_loss: -54.8393 - val_branch_severity_loss: -11.2606 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: -74.4051 - branch_intent_loss: -8.4435 - branch_emotion_loss: -55.9651 - branch_severity_loss: -9.9966 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -77.6790 - val_branch_intent_loss: -7.7333 - val_branch_emotion_loss: -57.8590 - val_branch_severity_loss: -12.0867 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: -78.9486 - branch_intent_loss: -9.1998 - branch_emotion_loss: -59.0277 - branch_severity_loss: -10.7212 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -82.2696 - val_branch_intent_loss: -8.3935 - val_branch_emotion_loss: -60.9162 - val_branch_severity_loss: -12.9598 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: -83.4568 - branch_intent_loss: -9.9798 - branch_emotion_loss: -62.0057 - branch_severity_loss: -11.4712 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -86.7049 - val_branch_intent_loss: -9.0166 - val_branch_emotion_loss: -63.8421 - val_branch_severity_loss: -13.8462 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: -87.7812 - branch_intent_loss: -10.6936 - branch_emotion_loss: -64.8381 - branch_severity_loss: -12.2494 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -90.9686 - val_branch_intent_loss: -9.6465 - val_branch_emotion_loss: -66.5757 - val_branch_severity_loss: -14.7465 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: -91.8748 - branch_intent_loss: -11.3800 - branch_emotion_loss: -67.4866 - branch_severity_loss: -13.0082 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -95.0211 - val_branch_intent_loss: -10.2427 - val_branch_emotion_loss: -69.1603 - val_branch_severity_loss: -15.6181 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: -95.8758 - branch_intent_loss: -12.0614 - branch_emotion_loss: -70.0544 - branch_severity_loss: -13.7600 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -98.9701 - val_branch_intent_loss: -10.8041 - val_branch_emotion_loss: -71.6914 - val_branch_severity_loss: -16.4745 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: -99.7630 - branch_intent_loss: -12.7107 - branch_emotion_loss: -72.5556 - branch_severity_loss: -14.4967 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -102.9003 - val_branch_intent_loss: -11.3862 - val_branch_emotion_loss: -74.1769 - val_branch_severity_loss: -17.3371 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: -103.6170 - branch_intent_loss: -13.3654 - branch_emotion_loss: -75.0207 - branch_severity_loss: -15.2309 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -106.7580 - val_branch_intent_loss: -11.9404 - val_branch_emotion_loss: -76.6356 - val_branch_severity_loss: -18.1821 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: -107.4537 - branch_intent_loss: -14.0180 - branch_emotion_loss: -77.4717 - branch_severity_loss: -15.9640 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -110.5993 - val_branch_intent_loss: -12.5001 - val_branch_emotion_loss: -79.0632 - val_branch_severity_loss: -19.0361 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: -111.2417 - branch_intent_loss: -14.6656 - branch_emotion_loss: -79.8797 - branch_severity_loss: -16.6964 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -114.4331 - val_branch_intent_loss: -13.0719 - val_branch_emotion_loss: -81.4846 - val_branch_severity_loss: -19.8765 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 29ms/step - loss: -115.0247 - branch_intent_loss: -15.3126 - branch_emotion_loss: -82.2872 - branch_severity_loss: -17.4248 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -118.2531 - val_branch_intent_loss: -13.6277 - val_branch_emotion_loss: -83.8895 - val_branch_severity_loss: -20.7359 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: -118.7833 - branch_intent_loss: -15.9608 - branch_emotion_loss: -84.6616 - branch_severity_loss: -18.1609 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -121.9887 - val_branch_intent_loss: -14.1895 - val_branch_emotion_loss: -86.2453 - val_branch_severity_loss: -21.5539 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: -122.4789 - branch_intent_loss: -16.6197 - branch_emotion_loss: -87.0028 - branch_severity_loss: -18.8564 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -125.7252 - val_branch_intent_loss: -14.7600 - val_branch_emotion_loss: -88.5938 - val_branch_severity_loss: -22.3714 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 29ms/step - loss: -126.1949 - branch_intent_loss: -17.2730 - branch_emotion_loss: -89.3663 - branch_severity_loss: -19.5556 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -129.4647 - val_branch_intent_loss: -15.3201 - val_branch_emotion_loss: -90.9526 - val_branch_severity_loss: -23.1920 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 41ms/step - loss: -129.8997 - branch_intent_loss: -17.9116 - branch_emotion_loss: -91.7221 - branch_severity_loss: -20.2660 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -133.1999 - val_branch_intent_loss: -15.8892 - val_branch_emotion_loss: -93.3104 - val_branch_severity_loss: -24.0002 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 34ms/step - loss: -133.5857 - branch_intent_loss: -18.5510 - branch_emotion_loss: -94.0729 - branch_severity_loss: -20.9618 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -136.9071 - val_branch_intent_loss: -16.4536 - val_branch_emotion_loss: -95.6530 - val_branch_severity_loss: -24.8006 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: -137.2197 - branch_intent_loss: -19.1940 - branch_emotion_loss: -96.3767 - branch_severity_loss: -21.6490 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -140.6088 - val_branch_intent_loss: -16.9781 - val_branch_emotion_loss: -97.9927 - val_branch_severity_loss: -25.6379 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 29ms/step - loss: -140.8687 - branch_intent_loss: -19.8054 - branch_emotion_loss: -98.7004 - branch_severity_loss: -22.3630 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -144.2859 - val_branch_intent_loss: -17.5420 - val_branch_emotion_loss: -100.2964 - val_branch_severity_loss: -26.4476 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: -144.5137 - branch_intent_loss: -20.4571 - branch_emotion_loss: -100.9976 - branch_severity_loss: -23.0590 - branch_intent_accuracy: 0.2086 - branch_emotion_accuracy: 0.1273 - branch_severity_accuracy: 0.2163 - val_loss: -147.9176 - val_branch_intent_loss: -18.0838 - val_branch_emotion_loss: -102.5791 - val_branch_severity_loss: -27.2548 - val_branch_intent_accuracy: 0.2256 - val_branch_emotion_accuracy: 0.0915 - val_branch_severity_accuracy: 0.1768\n",
      "7/7 [==============================] - 0s 11ms/step - loss: -149.1822 - branch_intent_loss: -20.2206 - branch_emotion_loss: -106.6928 - branch_severity_loss: -22.2688 - branch_intent_accuracy: 0.3024 - branch_emotion_accuracy: 0.0878 - branch_severity_accuracy: 0.2293\n",
      "Test Loss: [-149.18223571777344, -20.220632553100586, -106.69279479980469, -22.268795013427734, 0.30243903398513794, 0.08780487626791, 0.22926829755306244]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming your DataFrame is named data\n",
    "# Select relevant columns\n",
    "df_subset = data[[\"Complaint/ Opinion\", \"Intent\", \"Emotion\", \"Severity level\"]]\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder_intent = LabelEncoder()\n",
    "df_subset[\"Intent\"] = label_encoder_intent.fit_transform(df_subset[\"Intent\"])\n",
    "\n",
    "label_encoder_emotion = LabelEncoder()\n",
    "df_subset[\"Emotion\"] = label_encoder_emotion.fit_transform(df_subset[\"Emotion\"])\n",
    "\n",
    "label_encoder_severity = LabelEncoder()\n",
    "df_subset[\"Severity level\"] = label_encoder_severity.fit_transform(df_subset[\"Severity level\"])\n",
    "\n",
    "# Tokenize text data\n",
    "max_words = 1000  # adjust as needed\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(df_subset[\"Complaint/ Opinion\"].values)\n",
    "X = tokenizer.texts_to_sequences(df_subset[\"Complaint/ Opinion\"].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_intent, y_test_intent, y_train_emotion, y_test_emotion, y_train_severity, y_test_severity = train_test_split(\n",
    "    X, df_subset[\"Intent\"].values, df_subset[\"Emotion\"].values, df_subset[\"Severity level\"].values,\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "embedding_dim = 50  # adjust as needed\n",
    "lstm_units = 50  # adjust as needed\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=X.shape[1])(input_layer)\n",
    "lstm_layer = LSTM(lstm_units)(embedding_layer)\n",
    "intent_output = Dense(1, activation='sigmoid', name='branch_intent')(lstm_layer)\n",
    "emotion_output = Dense(1, activation='sigmoid', name='branch_emotion')(lstm_layer)\n",
    "severity_output = Dense(1, activation='sigmoid', name='branch_severity')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[intent_output, emotion_output, severity_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'branch_intent': y_train_intent, 'branch_emotion': y_train_emotion, 'branch_severity': y_train_severity},\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(\n",
    "    X_test,\n",
    "    {'branch_intent': y_test_intent, 'branch_emotion': y_test_emotion, 'branch_severity': y_test_severity}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9a64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51a5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
